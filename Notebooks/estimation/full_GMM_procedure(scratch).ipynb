{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full GMM procedure: parameters to entropy to lambda to (finally) moment errors\n",
    "\n",
    "This notebooks aims to have a complete GMM estimation procedure.\n",
    "It goes:\n",
    "\n",
    "+ 1) the structural parameters and data $(\\theta, Z)$\n",
    "+ 2) Entropy of initial lambdas ($\\lambda_0$) and the expected value of ($\\lambda_0$)  is a function of data and structural parameters. $H = f( \\theta' Z)$, $E[B] = g(\\theta' Z)$\n",
    "+ 3) ($\\lambda_0$)  is a vector that is a function of entropy and expected value. $\\lambda_0 = K(H, E[B])$\n",
    "+ 4) The simulated moments is a function of ($\\lambda_0$). $M = L(\\lambda_0)$. Kalman filter might help me do something better :D\n",
    "\n",
    "This involves two steps\n",
    "\n",
    "+ I) Numerical prrocedure to get ($\\lambda_0$) from $(\\theta_{try}, Z)$, through $(H, E[B])$.\n",
    "+ II) (Numerical?) procedure to get simulated moments from ($\\lambda_0$).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I) Numerical procedure to get ($\\lambda_0$) from $(\\theta_{try}, Z)$\n",
    "\n",
    "through $(H, E[B])$. See `unique_lambdas_from_H.ipynb` for more details\n",
    "\n",
    "It makes sense to have a multiple starting point thingy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3, 0.5, 0.19999999999999996]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.3, 0.5, 0.2])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def force_sum_to_1(x):\n",
    "    \"\"\"\n",
    "    Forces lambdas to sum to 1\n",
    "    Only works for three lambdas\n",
    "    \"\"\"\n",
    "    return [x[0], x[1], 1 - x[0] - x[1]]\n",
    "\n",
    "\n",
    "def force_sum_to_1_(x):\n",
    "    return np.hstack([x, 1-x.sum()])\n",
    "\n",
    "x = np.array([0.3, 0.5])\n",
    "print(force_sum_to_1(x))\n",
    "force_sum_to_1_(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The solution converged.\n",
      "[0.05273249 0.64453502 0.30273249]\n",
      "target values for objective:  0.8 1.2\n",
      "Solution values for objective: 0.80, 1.20\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import optimize\n",
    "\n",
    "#Parameters\n",
    "Eβ = 1.2\n",
    "βs = [0.7, 1.1, 1.5] # Corresponding to each lambda\n",
    "H = 0.8\n",
    "\n",
    "def my_entropy(p):\n",
    "    return -np.sum(p * np.log(p))\n",
    "\n",
    "\n",
    "def force_sum_to_1(x):\n",
    "    \"\"\"\n",
    "    Forces lambdas to sum to 1\n",
    "    (although last element might be negative)\n",
    "    \"\"\"\n",
    "    return np.hstack([x, 1-x.sum()])\n",
    "\n",
    "\n",
    "def logit(p):\n",
    "    return np.log(p / (1 - p))\n",
    "\n",
    "\n",
    "def reparam_lambdas(x):\n",
    "    \"\"\" inverse logit. Forces the lambdas to be within 0 and 1\"\"\"\n",
    "    return np.e**x / (1 + np.e**x)\n",
    "\n",
    "\n",
    "def fun(x, βs, Eβ, H):\n",
    "    \"\"\"\n",
    "    x: deep parameters\n",
    "    Eβ, H: the objectives\n",
    "    βs: fixed constant of the model\n",
    "    \"\"\"\n",
    "    lambdas = force_sum_to_1(reparam_lambdas(x))\n",
    "    return [my_entropy(lambdas) - H,\n",
    "            np.dot(βs, lambdas) - Eβ]\n",
    "\n",
    "def jac(x, βs):\n",
    "    \"\"\"\n",
    "    Jacobian for reparametrization of lambdas.\n",
    "    Code for only three lambdas\n",
    "    \"\"\"\n",
    "    # Derivatives wrt to H\n",
    "    block = np.log((1 - np.e ** (x[0] + x[1])) / (np.e ** (x[0]) + np.e ** (x[1]) + np.e ** (x[0] + x[1]) + 1))\n",
    "    num0 = (-np.log(np.e ** x[0] / (np.e ** x[0] + 1)) + block) * np.e ** x[0]\n",
    "    den0 = np.e ** (2 * x[0]) + 2 * np.e ** (x[0]) + 1\n",
    "    num1 = (-np.log(np.e ** x[1] / (np.e ** x[1] + 1)) + block) * np.e ** x[1]\n",
    "    den1 = np.e ** (2 * x[1]) + 2 * np.e ** (x[1]) + 1\n",
    "\n",
    "    dh_dx = np.array([num0 / den0, num1 / den1])\n",
    "\n",
    "    # Derivatives wrt E[B]\n",
    "    deb_0 = ((βs[0] - βs[2]) * np.e ** (-x[0])) / (1 + np.e ** (-x[0])) ** 2\n",
    "    deb_1 = ((βs[1] - βs[2]) * np.e ** (-x[1])) / (1 + np.e ** (-x[1])) ** 2\n",
    "    deb_dx = np.array([deb_0, deb_1])\n",
    "\n",
    "    return np.array([dh_dx, deb_dx])\n",
    "\n",
    "def relative_error(true, solution):\n",
    "    \"\"\"\n",
    "    Average relative error to discriminate solutions\n",
    "    \"\"\"\n",
    "    return np.mean(2*np.abs((true - solution) / (true + solution)))\n",
    "\n",
    "\n",
    "def fun_(x):\n",
    "    return fun(x, βs=βs, Eβ=Eβ, H=H)\n",
    "\n",
    "\n",
    "def jac_(x):\n",
    "    return jac(x, βs=βs)\n",
    "\n",
    "sol = optimize.root(fun_, logit(np.array([0.1, 0.5])), jac=jac_)\n",
    "print(sol.message)\n",
    "\n",
    "lambdas_sol = force_sum_to_1(reparam_lambdas(sol.x))\n",
    "print(lambdas_sol)\n",
    "print(\"target values for objective: \", H, Eβ)\n",
    "print(f\"Solution values for objective: {my_entropy(lambdas_sol):.2f},\"\n",
    "      + f\" {np.dot(βs, lambdas_sol):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target values for objective:  0.8 1.2\n",
      "  \n",
      "x0: [0.1 0.2]\n",
      "['0.355', '0.040', '0.605']\n",
      "Solution values for objective: 0.80 , 1.20\n",
      "Error:    2.6e-14\n",
      "=========================================\n",
      " \n",
      "x0: [0.3 0.3]\n",
      "['0.355', '0.040', '0.605']\n",
      "Solution values for objective: 0.80 , 1.20\n",
      "Error:    1.5e-13\n",
      "=========================================\n",
      " \n",
      "x0: [0.25 0.45]\n",
      "['0.053', '0.645', '0.303']\n",
      "Solution values for objective: 0.80 , 1.20\n",
      "Error:    1.1e-14\n",
      "=========================================\n",
      " \n",
      "x0: [0.45 0.25]\n",
      "['0.355', '0.040', '0.605']\n",
      "Solution values for objective: 0.80 , 1.20\n",
      "Error:    1.1e-12\n",
      "=========================================\n",
      " \n"
     ]
    }
   ],
   "source": [
    "starting_points = np.array([[0.1, 0.2], [0.3, 0.3],\n",
    "                           [0.25, 0.45], [0.45, 0.25]])\n",
    "\n",
    "def ndprint(a, format_string='{0:.3f}'):\n",
    "    print([format_string.format(v,i) for i,v in enumerate(a)])\n",
    "\n",
    "target = np.array([H, Eβ])\n",
    "print(\"target values for objective: \", target[0], target[1])\n",
    "print(\"  \")\n",
    "for x0 in starting_points:\n",
    "    print(f\"x0: {x0}\")\n",
    "    sol = optimize.root(fun, logit(x0), jac=jac)\n",
    "    lambdas_sol = x_to_lambdas(x_to_p(sol.x))\n",
    "    ndprint(np.array(lambdas_sol))\n",
    "    solution = np.array([my_entropy(lambdas_sol), np.dot(βs, lambdas_sol)])\n",
    "    print(f\"Solution values for objective: {solution[0]:.2f} ,\"\n",
    "      + f\" {solution[1]:.2f}\")\n",
    "    print(f\"Error: {relative_error(target, solution):10.1e}\")\n",
    "    print(\"=========================================\")\n",
    "    print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(lambdas_sol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.4,  0.8,  0.3, -0.5])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "#x -> [x[0], x[1], 1 - x[0] - x[1]]\n",
    "x = np.array([0.4, 0.8, 0.3])\n",
    "z = np.hstack([x, 1-x.sum()])\n",
    "z\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II) (Numerical?) procedure to get simulated moments from ($\\lambda_0$).\n",
    "\n",
    "See `gmm_example.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing done. Now starting optimization\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import dill\n",
    "import pandas as pd\n",
    "from scipy import optimize as opt\n",
    "import time\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "import src\n",
    "\n",
    "\n",
    "#Load policy and value function\n",
    "#####################\n",
    "file_n = \"2018-10-5vfi_dict.dill\"\n",
    "with open('../../data/' + file_n, 'rb') as file:\n",
    "    data_d = dill.load(file)\n",
    "\n",
    "lambdas = src.generate_simplex_3dims(n_per_dim=data_d['n_of_lambdas_per_dim'])\n",
    "price_grid = np.linspace(data_d['min_price'], data_d['max_price'])\n",
    "\n",
    "policy = data_d['policy']\n",
    "valueF = data_d['valueF']\n",
    "lambdas_ext = src.generate_simplex_3dims(n_per_dim=\n",
    "                                         data_d['n_of_lambdas_per_dim'])\n",
    "\n",
    "#Interpolate policy (level price). valueF is already a function\n",
    "policyF = src.interpolate_wguess(lambdas_ext, policy)\n",
    "\n",
    "\n",
    "# Simulation parameters \\\n",
    "########################\n",
    "σerror= 0.005 #0.01\n",
    "Nfirms = 300\n",
    "time_periods = 40\n",
    "min_periods= 3\n",
    "\n",
    "#Suitable for logistic\n",
    "β10, β11 = -2., 3.\n",
    "β20, β21 = 0.03, -2.\n",
    "betas = [β10, β11, β20, β21]\n",
    "\n",
    "#GMM parameters\n",
    "maxiters = 3\n",
    "\n",
    "\n",
    "def lambda_0(x, prior_shock) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Generate a vector of lambdas on the observables x\n",
    "    \"\"\"\n",
    "    return src.from_theta_to_lambda0(x, θ=betas, prior_shock=prior_shock)\n",
    "\n",
    "\n",
    "xs = np.abs(np.random.normal(0, 0.18, size=Nfirms))\n",
    "prior_shocks = src.gen_prior_shocks(Nfirms, σerror=σerror)\n",
    "\n",
    "dmd_shocks = src.generate_dmd_shocks(n=Nfirms, t=time_periods, dmd_σϵ=src.const.σ_ɛ)\n",
    "\n",
    "df = src.simulate_all_firms(Nfirms, valueF, policyF, xs, θ=betas,\n",
    "                   dmd_shocks=dmd_shocks, prior_shocks=prior_shocks)\n",
    "\n",
    "std_devs = (df.groupby('firm').level_prices.rolling(window=4, min=3)\n",
    "            .std().reset_index()\n",
    "            .rename(columns={'level_1': 't',\n",
    "                            'level_prices': 'std_dev_prices'}))\n",
    "\n",
    "df = pd.merge(df, std_devs, on=['firm', 't'], how='left')\n",
    "\n",
    "mean_std_observed_prices = df.groupby('t').std_dev_prices.mean()[min_periods:]\n",
    "\n",
    "\n",
    "def error_w_data(θ) -> float:\n",
    "    return src.gmm_error(θ, policyF, xs,\n",
    "                      mean_std_observed_prices=mean_std_observed_prices, df=df,\n",
    "                                 prior_shocks=prior_shocks, min_periods=min_periods)\n",
    "\n",
    "print(\"Preprocessing done. Now starting optimization\")\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "optimi = opt.differential_evolution(error_w_data, [(-2.5, 0.5), (3., 3.2),\n",
    "                                                   (-0.5, 0.2), (-3, 1)],\n",
    "                                    maxiter=maxiters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III) Putting step 1 and 2 together\n",
    "\n",
    "get_lambdas_from_x uses lambda_0(x, prior_shock)??\n",
    "\n",
    "\n",
    "I think I only need to change `src.from_theta_to_lambda0` to include the intermediate step\n",
    "through H, E[B]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:learningenv]",
   "language": "python",
   "name": "conda-env-learningenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
