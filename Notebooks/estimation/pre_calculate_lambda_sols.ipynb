{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre calculate Lambda solutions\n",
    "\n",
    "Given a $H, E[\\beta]$ input, we find the three-dimensional lambda solution.\n",
    "\n",
    "Find k by k solutions, then find a smart, fast way to do the lookup\n",
    "The lookup should find the row and column index where the solution lies\n",
    "and also the four quadrants.\n",
    "\n",
    "These solution take src.betas_transition as given, so can't be used for\n",
    "different values of these"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numba import njit\n",
    "from scipy.stats import entropy\n",
    "from scipy import optimize\n",
    "from scipy.spatial.distance import euclidean\n",
    "\n",
    "#Constants\n",
    "betas_transition = np.array([-4., -2., -1.1])\n",
    "\n",
    "\n",
    "def reparam_lambdas(x):\n",
    "    \"\"\"\n",
    "    uses softmax to get values between 0 and 1\n",
    "    and make them sum to 1\n",
    "    \"\"\"\n",
    "    #return np.exp(x) / np.sum(np.exp(x))\n",
    "    #Numerically more stable version\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum()\n",
    "\n",
    "\n",
    "#@njit()\n",
    "def h_and_exp_betas_eqns(orig_lambdas, βs, Eβ, H, w=np.array([[1., 0.], [0., 1./4.]])):\n",
    "    \"\"\"\n",
    "    orig_lambdas: original lambda tries (not summing to zero, not within [0, 1])\n",
    "    Eβ, H: the objectives\n",
    "    βs: fixed constant of the model\n",
    "    \"\"\"\n",
    "    lambdas = reparam_lambdas(orig_lambdas)\n",
    "    g = np.array([entropy(lambdas) - H, np.dot(βs, lambdas) - Eβ])\n",
    "    return g.T @ w @ g\n",
    "\n",
    "\n",
    "def H_and_eb_to_lambda0(H, Eβ,\n",
    "                        starting_values=np.array([0.1, 1.5, 1.])):\n",
    "    \"\"\"\n",
    "    Generates a lambda0 vector from the values of\n",
    "    the entropy and expected value of betas (H, EB)\n",
    "    \"\"\"\n",
    "\n",
    "    def fun_(lambda_try):\n",
    "        return h_and_exp_betas_eqns(lambda_try, betas_transition, Eβ, H)\n",
    "\n",
    "    sol = optimize.minimize(fun_, x0=starting_values, method='Powell')\n",
    "    lambdas_sol = reparam_lambdas(sol.x)\n",
    "    if not sol.success:\n",
    "        # Use Nelder-Mead from different starting_value\n",
    "        sol = optimize.minimize(fun_, x0=np.array([1.6, 0.1, 0.25]),\n",
    "                                method='Nelder-Mead')\n",
    "        lambdas_sol = reparam_lambdas(sol.x)\n",
    "        if not sol.success:\n",
    "            print(f\"Theta to lambda0 didn't converge\", sol.x, lambdas_sol)\n",
    "\n",
    "    return lambdas_sol\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(115, 290)\n"
     ]
    }
   ],
   "source": [
    "# Get candidates rows and cols\n",
    "h_bounds = [0, np.log(3) + 0.05]\n",
    "eb_bounds = [betas_transition[0], betas_transition[-1]]\n",
    "\n",
    "h_n_digits_precision = 3\n",
    "eb_n_digits_precision = 3\n",
    "h_digit_precision = 0.01\n",
    "eb_digit_precision = 0.01\n",
    "h_candidates = np.arange(h_bounds[0], h_bounds[1], h_digit_precision)\n",
    "eb_candidates = np.arange(eb_bounds[0], eb_bounds[1], eb_digit_precision)\n",
    "grid_size = (len(h_candidates), len(eb_candidates))\n",
    "grid_total_elements = grid_size[0]*grid_size[1]\n",
    "lambda_values = np.empty((grid_size[0], grid_size[1], 3), dtype=np.float64)\n",
    "print(grid_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.142026197910309 minutos para array de tamaño (115, 290) o 33350 elementos\n"
     ]
    }
   ],
   "source": [
    "# Find values for candidates\n",
    "import time\n",
    "start = time.time()\n",
    "\n",
    "for i_h, h in enumerate(h_candidates):\n",
    "    for i_eb, eb in enumerate(eb_candidates):\n",
    "        lambda_values[i_h, i_eb, :] = H_and_eb_to_lambda0(h, eb)\n",
    "        \n",
    "secs_it_took = time.time() - start\n",
    "print(f\"{secs_it_took / 60} minutos para array de tamaño {grid_size} o {grid_size[0]* grid_size[1]} elementos\")\n",
    "\n",
    "secs_por_element =  secs_it_took / grid_total_elements \n",
    "print(f\"tomó {secs_por_element} minutos por valor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary for quick lookup\n",
    "\n",
    "h_dict = {}\n",
    "for i in range(len(h_candidates)):\n",
    "    h_dict[np.round(h_candidates[i], h_n_digits_precision)] = i\n",
    "\n",
    "e_dict = {}\n",
    "for i in range(len(eb_candidates)):\n",
    "    e_dict[np.round(eb_candidates[i], eb_n_digits_precision)] = i\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([0.0, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.2, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.3, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.4, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.5, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.6, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.7, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.8, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, 0.9, 0.91, 0.92, 0.93, 0.94, 0.95, 0.96, 0.97, 0.98, 0.99, 1.0, 1.01, 1.02, 1.03, 1.04, 1.05, 1.06, 1.07, 1.08, 1.09, 1.1, 1.11, 1.12, 1.13, 1.14])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OLS coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.002408099160052836\n",
      "0.9365117449459819\n",
      "0.07218528485557224\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.formula.api as smf\n",
    "y1 = []\n",
    "y2 = []\n",
    "y3 = []\n",
    "h_x = []\n",
    "eb_x = []\n",
    "for i_h, h in enumerate(h_candidates):\n",
    "    for i_eb, eb in enumerate(eb_candidates):\n",
    "        y1_, y2_, y3_ = lambda_values[i_h, i_eb, :]\n",
    "        y1.append(y1_)\n",
    "        y2.append(y2_)\n",
    "        y3.append(y3_)\n",
    "        h_x.append(h)\n",
    "        eb_x.append(eb)\n",
    "        \n",
    "df = pd.DataFrame({'y1': y1, 'y2': y2, 'y3': y3,\n",
    "                  'h_x': h_x, 'eb_x': eb_x})\n",
    "\n",
    "df['h_x2'] = df.h_x**2\n",
    "df['eb_x2'] = df.eb_x**2\n",
    "\n",
    "formula1 = 'y1 ~ h_x * eb_x + h_x2*eb_x2 +  h_x2:eb_x - 1'\n",
    "modely1 = smf.ols(formula=formula1, data=df).fit()\n",
    "\n",
    "formula2 = 'y2 ~ h_x * eb_x + h_x2*eb_x2 + h_x2:eb_x- 1'\n",
    "modely2 = smf.ols(formula=formula2, data=df).fit()\n",
    "\n",
    "formula3 = 'y3 ~ h_x * eb_x + h_x2*eb_x2 + h_x2:eb_x - 1'\n",
    "modely3 = smf.ols(formula=formula3, data=df).fit()\n",
    "\n",
    "lambda1coeffs = modely1.params.values\n",
    "lambda2coeffs = modely2.params.values\n",
    "lambda3coeffs = modely3.params.values\n",
    "\n",
    "@njit(['float64(float64, float64, float64, float64, float64[:])'])\n",
    "def lambda_gen(h, eb, h2, eb2, lambdacoeffs):\n",
    "    return (lambdacoeffs[0]*h + lambdacoeffs[1]*eb + \n",
    "           lambdacoeffs[2]*h*eb + lambdacoeffs[3]*h2\n",
    "           + lambdacoeffs[4]*eb2 + lambdacoeffs[5]*(h2*eb2)\n",
    "           + lambdacoeffs[6]*(h2*eb))\n",
    "\n",
    "@njit(['float64[:](float64, float64, float64[:], float64[:], float64[:])'])\n",
    "def all_lambda_gen(h, eb, lcoeffs1, lcoeffs2, lcoeffs3):\n",
    "    h2 = h**2\n",
    "    eb2 = eb**2\n",
    "    return np.array([lambda_gen(h, eb, h2, eb2, lcoeffs1),\n",
    "                    lambda_gen(h, eb, h2, eb2, lcoeffs2),\n",
    "                    lambda_gen(h, eb, h2, eb2, lcoeffs3)])\n",
    "\n",
    "\n",
    "h = 0.2\n",
    "eb = -2.\n",
    "print(lambda_gen(h, eb, h**2, eb**2, lambda1coeffs))\n",
    "print(lambda_gen(h, eb, h**2, eb**2, lambda2coeffs))\n",
    "print(lambda_gen(h, eb, h**2, eb**2, lambda3coeffs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.0024081 ,  0.93651174,  0.07218528])"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_lambda_gen(h, eb, lambda1coeffs, lambda2coeffs, lambda3coeffs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save lambda_matrix_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "lambda_matrix_dict = {}\n",
    "lambda_matrix_dict['lambda_matrix'] = lambda_values\n",
    "lambda_matrix_dict['h_candidates'] = h_candidates\n",
    "lambda_matrix_dict['eb_candidates'] = eb_candidates\n",
    "lambda_matrix_dict['h_n_digits_precision'] = h_n_digits_precision\n",
    "lambda_matrix_dict['eb_n_digits_precision'] = eb_n_digits_precision\n",
    "lambda_matrix_dict['h_dict'] = h_dict\n",
    "lambda_matrix_dict['e_dict'] = e_dict\n",
    "    lambda_matrix_dict['lambda1coeffs'] = lambda1coeffs\n",
    "    lambda_matrix_dict['lambda2coeffs'] = lambda2coeffs\n",
    "    lambda_matrix_dict['lambda3coeffs'] = lambda3coeffs\n",
    "\n",
    "with open('../../data/lambda_matrix_dict.pickle', 'wb') as f:\n",
    "    pickle.dump(lambda_matrix_dict, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speeding up stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear interpolation\n",
    "\n",
    "Think of each $\\lambda$ as the $y$s and $H, eb$ as $x_1, x_2$ \n",
    "\n",
    "for $y_1, y_2, y_3 $:\n",
    "\n",
    "$$ y_1 = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_1^2 + \\beta_3 x_2 + \\beta_4 x_2^2 + \\beta_5 x_1x_2 + \\beta_6 x_1^2 x_2 + \\beta_7 x_1 x_2^2 $$\n",
    "\n",
    "Store those $7*3 = 21$ coefficients and your $f$ will be just this.\n",
    "It's important to verify that this linear regression function has relatively good $R^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(115, 290, 3)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.002408099160052836\n",
      "0.9365117449459819\n",
      "0.07218528485557224\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78.7 µs ± 841 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "input_heb_to_lambda_con_norm(input_point, lambda_values, h_candidates, eb_candidates,\n",
    "                                 h_n_digits_precision, eb_n_digits_precision,\n",
    "                                 h_dict, e_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypingError",
     "evalue": "Failed in nopython mode pipeline (step: nopython frontend)\nInternal error at <numba.typeinfer.ArgConstraint object at 0x11fd6b860>:\n--%<----------------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/usr/local/anaconda3/envs/spike_basicoV3/lib/python3.6/site-packages/numba/errors.py\", line 609, in new_error_context\n    yield\n  File \"/usr/local/anaconda3/envs/spike_basicoV3/lib/python3.6/site-packages/numba/typeinfer.py\", line 198, in __call__\n    assert ty.is_precise()\nAssertionError\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/local/anaconda3/envs/spike_basicoV3/lib/python3.6/site-packages/numba/typeinfer.py\", line 141, in propagate\n    constraint(typeinfer)\n  File \"/usr/local/anaconda3/envs/spike_basicoV3/lib/python3.6/site-packages/numba/typeinfer.py\", line 199, in __call__\n    typeinfer.add_type(self.dst, ty, loc=self.loc)\n  File \"/usr/local/anaconda3/envs/spike_basicoV3/lib/python3.6/contextlib.py\", line 99, in __exit__\n    self.gen.throw(type, value, traceback)\n  File \"/usr/local/anaconda3/envs/spike_basicoV3/lib/python3.6/site-packages/numba/errors.py\", line 617, in new_error_context\n    six.reraise(type(newerr), newerr, tb)\n  File \"/usr/local/anaconda3/envs/spike_basicoV3/lib/python3.6/site-packages/numba/six.py\", line 659, in reraise\n    raise value\nnumba.errors.InternalError: \u001b[1m\u001b[1m\u001b[0m\n\u001b[0m\u001b[1m[1] During: typing of argument at <ipython-input-115-4e100c1b96ef> (72)\u001b[0m\n--%<----------------------------------------------------------------------------\n\n\u001b[1m\nFile \"<ipython-input-115-4e100c1b96ef>\", line 72:\u001b[0m\n\u001b[1mdef nb_input_heb_to_lambda_con_norm(input_point, lambda_values, h_candidates, eb_candidates,\n    <source elided>\n    \"\"\"\n\u001b[1m    H, eb = input_point[0], input_point[1]\n\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n\nThis error may have been caused by the following argument(s):\n- argument 6: \u001b[1mcannot determine Numba type of <class 'dict'>\u001b[0m\n- argument 7: \u001b[1mcannot determine Numba type of <class 'dict'>\u001b[0m\n\nThis is not usually a problem with Numba itself but instead often caused by\nthe use of unsupported features or an issue in resolving types.\n\nTo see Python/NumPy features supported by the latest release of Numba visit:\nhttp://numba.pydata.org/numba-doc/dev/reference/pysupported.html\nand\nhttp://numba.pydata.org/numba-doc/dev/reference/numpysupported.html\n\nFor more information about typing errors and how to debug them visit:\nhttp://numba.pydata.org/numba-doc/latest/user/troubleshoot.html#my-code-doesn-t-compile\n\nIf you think your code should work with Numba, please report the error message\nand traceback, along with a minimal reproducer at:\nhttps://github.com/numba/numba/issues/new\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypingError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-116-496e768c51f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m nb_input_heb_to_lambda_con_norm(input_point, lambda_values, h_candidates, eb_candidates,\n\u001b[1;32m      2\u001b[0m                                  \u001b[0mh_n_digits_precision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meb_n_digits_precision\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                                  h_dict, e_dict)\n\u001b[0m",
      "\u001b[0;32m/usr/local/anaconda3/envs/spike_basicoV3/lib/python3.6/site-packages/numba/dispatcher.py\u001b[0m in \u001b[0;36m_compile_for_args\u001b[0;34m(self, *args, **kws)\u001b[0m\n\u001b[1;32m    346\u001b[0m                 \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 348\u001b[0;31m             \u001b[0merror_rewrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'typing'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnsupportedError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m             \u001b[0;31m# Something unsupported is present in the user code, add help info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/spike_basicoV3/lib/python3.6/site-packages/numba/dispatcher.py\u001b[0m in \u001b[0;36merror_rewrite\u001b[0;34m(e, issue_type)\u001b[0m\n\u001b[1;32m    313\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m                 \u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0margtypes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/spike_basicoV3/lib/python3.6/site-packages/numba/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    656\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 658\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    659\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypingError\u001b[0m: Failed in nopython mode pipeline (step: nopython frontend)\nInternal error at <numba.typeinfer.ArgConstraint object at 0x11fd6b860>:\n--%<----------------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/usr/local/anaconda3/envs/spike_basicoV3/lib/python3.6/site-packages/numba/errors.py\", line 609, in new_error_context\n    yield\n  File \"/usr/local/anaconda3/envs/spike_basicoV3/lib/python3.6/site-packages/numba/typeinfer.py\", line 198, in __call__\n    assert ty.is_precise()\nAssertionError\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/local/anaconda3/envs/spike_basicoV3/lib/python3.6/site-packages/numba/typeinfer.py\", line 141, in propagate\n    constraint(typeinfer)\n  File \"/usr/local/anaconda3/envs/spike_basicoV3/lib/python3.6/site-packages/numba/typeinfer.py\", line 199, in __call__\n    typeinfer.add_type(self.dst, ty, loc=self.loc)\n  File \"/usr/local/anaconda3/envs/spike_basicoV3/lib/python3.6/contextlib.py\", line 99, in __exit__\n    self.gen.throw(type, value, traceback)\n  File \"/usr/local/anaconda3/envs/spike_basicoV3/lib/python3.6/site-packages/numba/errors.py\", line 617, in new_error_context\n    six.reraise(type(newerr), newerr, tb)\n  File \"/usr/local/anaconda3/envs/spike_basicoV3/lib/python3.6/site-packages/numba/six.py\", line 659, in reraise\n    raise value\nnumba.errors.InternalError: \u001b[1m\u001b[1m\u001b[0m\n\u001b[0m\u001b[1m[1] During: typing of argument at <ipython-input-115-4e100c1b96ef> (72)\u001b[0m\n--%<----------------------------------------------------------------------------\n\n\u001b[1m\nFile \"<ipython-input-115-4e100c1b96ef>\", line 72:\u001b[0m\n\u001b[1mdef nb_input_heb_to_lambda_con_norm(input_point, lambda_values, h_candidates, eb_candidates,\n    <source elided>\n    \"\"\"\n\u001b[1m    H, eb = input_point[0], input_point[1]\n\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n\nThis error may have been caused by the following argument(s):\n- argument 6: \u001b[1mcannot determine Numba type of <class 'dict'>\u001b[0m\n- argument 7: \u001b[1mcannot determine Numba type of <class 'dict'>\u001b[0m\n\nThis is not usually a problem with Numba itself but instead often caused by\nthe use of unsupported features or an issue in resolving types.\n\nTo see Python/NumPy features supported by the latest release of Numba visit:\nhttp://numba.pydata.org/numba-doc/dev/reference/pysupported.html\nand\nhttp://numba.pydata.org/numba-doc/dev/reference/numpysupported.html\n\nFor more information about typing errors and how to debug them visit:\nhttp://numba.pydata.org/numba-doc/latest/user/troubleshoot.html#my-code-doesn-t-compile\n\nIf you think your code should work with Numba, please report the error message\nand traceback, along with a minimal reproducer at:\nhttps://github.com/numba/numba/issues/new\n"
     ]
    }
   ],
   "source": [
    "nb_input_heb_to_lambda_con_norm(input_point, lambda_values, h_candidates, eb_candidates,\n",
    "                                 h_n_digits_precision, eb_n_digits_precision,\n",
    "                                 h_dict, e_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "input_point = np.array([0.2134, -3.977])\n",
    "#Find row, col\n",
    "H, eb = input_point[0], input_point[1]\n",
    "row = h_dict[np.round(H, h_n_digits_precision-1)]\n",
    "col = e_dict[np.round(eb, eb_n_digits_precision-1)]\n",
    "distances = numba_from_input_heb_to_lambda(input_point, row, col, lambda_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H, eb = input_point[0], input_point[1]\n",
    "row = h_dict[np.round(H, h_n_digits_precision-1)]\n",
    "col = e_dict[np.round(eb, eb_n_digits_precision-1)]\n",
    "stacked_values = numba_from_input_heb_to_lambda(input_point, row, col, lambda_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def from_input_heb_to_lambda(input_point, lambda_values, h_candidates, eb_candidates,\n",
    "                                h_n_digits_precision, eb_n_digits_precision):\n",
    "    H, eb = input_point[0], input_point[1]\n",
    "    #Find row, col\n",
    "    row = h_dict[np.round(H, h_n_digits_precision-1)]\n",
    "    col = e_dict[np.round(eb, eb_n_digits_precision-1)]\n",
    "\n",
    "    # Distances to row-1, row, row+1 and col-1, col, col+1\n",
    "    dist_row = np.array([np.abs(H - h_candidates[row - 1]), np.abs(H - h_candidates[row]), \n",
    "               np.abs(H - h_candidates[row + 1])])\n",
    "    if np.argmax(dist_row) == 2:\n",
    "        relevant_rows = [row-1, row]\n",
    "        dist_row = dist_row[0:2]\n",
    "    elif np.argmax(dist_row) == 0:\n",
    "        relevant_rows = [row, row+1]\n",
    "        dist_row = dist_row[1::]\n",
    "\n",
    "    dist_col = np.array([np.abs(eb- eb_candidates[col - 1]), np.abs(eb - eb_candidates[col]), \n",
    "               np.abs(eb - eb_candidates[col + 1])])\n",
    "    if np.argmax(dist_col) == 2:\n",
    "        relevant_cols = [col-1, col]\n",
    "        dist_col = dist_col[0:2]\n",
    "    elif np.argmax(dist_col) == 0:\n",
    "        relevant_cols = [col, col+1]\n",
    "        dist_col = dist_col[1::]\n",
    "\n",
    "    pointA, pointB = [relevant_rows[0], relevant_cols[0]], [relevant_rows[0], relevant_cols[1]]\n",
    "    pointC, pointD = [relevant_rows[1], relevant_cols[0]], [relevant_rows[1], relevant_cols[1]]\n",
    "    points = [pointA, pointB, pointC, pointD]\n",
    "\n",
    "    pointA_value = lambda_values[relevant_rows[0], relevant_cols[0]]\n",
    "    pointB_value = lambda_values[relevant_rows[0], relevant_cols[1]]\n",
    "    pointC_value = lambda_values[relevant_rows[1], relevant_cols[0]]\n",
    "    pointD_value = lambda_values[relevant_rows[1], relevant_cols[1]]\n",
    "    values = np.array([pointA_value, pointB_value, pointC_value, pointD_value])\n",
    "    distances = np.array([np.linalg.norm(input_point - point) for point in points])\n",
    "    distances /= distances.sum()\n",
    "    \n",
    "    #Linear combination of A, B, C, D points\n",
    "    return distances[np.newaxis, :]@values\n",
    "\n",
    "from numba import njit\n",
    "\n",
    "\n",
    "\n",
    "@njit()\n",
    "def numba_from_input_heb_to_lambda(input_point, row, col, lambda_values):\n",
    "    H, eb = input_point[0], input_point[1]\n",
    "\n",
    "    # Distances to row-1, row, row+1 and col-1, col, col+1\n",
    "    dist_row = np.array([np.abs(H - h_candidates[row - 1]), np.abs(H - h_candidates[row]), \n",
    "               np.abs(H - h_candidates[row + 1])])\n",
    "    if np.argmax(dist_row) == 2:\n",
    "        relevant_rows = [row-1, row]\n",
    "        dist_row = dist_row[0:2]\n",
    "    elif np.argmax(dist_row) == 0:\n",
    "        relevant_rows = [row, row+1]\n",
    "        dist_row = dist_row[1::]\n",
    "\n",
    "    dist_col = np.array([np.abs(eb- eb_candidates[col - 1]), np.abs(eb - eb_candidates[col]), \n",
    "               np.abs(eb - eb_candidates[col + 1])])\n",
    "    if np.argmax(dist_col) == 2:\n",
    "        relevant_cols = np.array([col-1, col])\n",
    "        dist_col = dist_col[0:2]\n",
    "    elif np.argmax(dist_col) == 0:\n",
    "        relevant_cols = np.array([col, col+1])\n",
    "        dist_col = dist_col[1::]\n",
    "\n",
    "    points = np.array([[relevant_rows[0], relevant_cols[0]], [relevant_rows[0], relevant_cols[1]],\n",
    "                       [relevant_rows[1], relevant_cols[0]], [relevant_rows[1], relevant_cols[1]]])\n",
    "\n",
    "    distances = np.array([np.linalg.norm(input_point - points[0]), np.linalg.norm(input_point - points[1]),\n",
    "                         np.linalg.norm(input_point - points[2]), np.linalg.norm(input_point - points[3])])\n",
    "    distances /= distances.sum()\n",
    "    \n",
    "    #Linear combination of A, B, C, D points\n",
    "    #return (distances.reshape((-1, 1)) @\\\n",
    "    #        np.array([lambda_values[relevant_rows[0], relevant_cols[0]], lambda_values[relevant_rows[0], relevant_cols[1]],\n",
    "    #                     lambda_values[relevant_rows[1], relevant_cols[0]], lambda_values[relevant_rows[1], relevant_cols[1]]]))\n",
    "    #return distances.reshape((-1, 1))\n",
    "    #return np.array([lambda_values[relevant_rows[0], relevant_cols[0]], lambda_values[relevant_rows[0], relevant_cols[1]],\n",
    "     #                    lambda_values[relevant_rows[1], relevant_cols[0]], lambda_values[relevant_rows[1], relevant_cols[1]]])\n",
    "    #return relevant_rows, relevant_cols\n",
    "    stacked_values = np.vstack((lambda_values[relevant_rows[0], relevant_cols[0]], lambda_values[relevant_rows[0], relevant_cols[1]],\n",
    "                         lambda_values[relevant_rows[1], relevant_cols[0]], lambda_values[relevant_rows[1], relevant_cols[1]]))\n",
    "\n",
    "    return stacked_values\n",
    "    #return distances.reshape((-1, 1)) @ stacked_values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:spike_basicoV3]",
   "language": "python",
   "name": "conda-env-spike_basicoV3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
